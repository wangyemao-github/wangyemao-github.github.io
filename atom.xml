<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wangyemao-github.github.io</id>
    <title>Gridea</title>
    <updated>2021-01-03T12:51:53.894Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wangyemao-github.github.io"/>
    <link rel="self" href="https://wangyemao-github.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://wangyemao-github.github.io/images/avatar.png</logo>
    <icon>https://wangyemao-github.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Flink State 之 KeyedState]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zhi-keyedstate/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zhi-keyedstate/">
        </link>
        <updated>2021-01-03T02:44:22.000Z</updated>
        <summary type="html"><![CDATA[<p>本文主要总结Flink State 中KeyedState，以及KeyedState的应用</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文主要总结Flink State 中KeyedState，以及KeyedState的应用</p>
<!-- more -->
<h1 id="keyedstate">KeyedState</h1>
<p>KeyedState在KeyedStream中使用。状态跟特定Key绑定的，即KeyedStream流上的每一个Key对应一个State对象。。</p>
<h2 id="keyedstate-支持的状态类型">KeyedState 支持的状态类型</h2>
<p>KeyedState可以使用所有Flink支持的State类型。FoldingState跟ReducingState类似，但是已标记为废弃，不建议再使用<br>
<img src="https://wangyemao-github.github.io/post-images/1609670108841.png" alt="" loading="lazy"></p>
<h2 id="statedescriptor">StateDescriptor</h2>
<p>对应于每一类State，Flink内部都设计了对应的<strong>StateDescriptor</strong>状态描述。它指定了状态的一些属性，包括：State名称，State中类型信息，序列化/反序列化器，State生存时间等。</p>
<h3 id="valuestatedescriptor定义">ValueStateDescriptor定义</h3>
<pre><code class="language-java">ValueStateDescriptor&lt;Tuple2&lt;Long,Long&gt;&gt; descriptor = 
              new ValueStateDescriptor&lt;&gt;(&quot;average&quot;,
                    TypeInformation.of(new TypeHint&lt;Tuple2&lt;Long,Long&gt;&gt;(){}),
                    Tuple2.of(0L,0L));
</code></pre>
<p>代码片段定义了一个ValueStateDescriptor，指定状态名称为“average”，状态类型为Tuple2&lt;Long,Long&gt;，默认值为：Tuple2&lt;0L,0L&gt;</p>
<h2 id="不同状态类型详细对比">不同状态类型详细对比</h2>
<table>
<thead>
<tr>
<th>State类型</th>
<th>存储数据类型</th>
<th>StateDescriptor</th>
<th>使用</th>
<th>操作</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueState<T></td>
<td>T类型的单值状态</td>
<td>ValueStateDescriptor<T></td>
<td>ValueState<T> getState(ValueStateDescriptor<T>)</td>
<td>更新：update(T);<br>获取：T value();</td>
<td>每一个Key与T类型状态值绑定</td>
</tr>
<tr>
<td>ListState<T></td>
<td>Key上的状态值为一个列表</td>
<td>ListStateDescriptor<T></td>
<td>ListState<T> getListState(ListStateDescriptor<T>)</td>
<td>追加数据：add(T)/addAll(List<T>);<br>获取状态数据列表：Iterable<T> get()</td>
<td></td>
</tr>
<tr>
<td>ReducingState<T></td>
<td>存储一个T类型的值</td>
<td>ReducingStateDescriptor<T></td>
<td>ReducingState<T> getReducingState(ReducingStateDescriptor<T>)</td>
<td>添加数据：add(T);</td>
<td>这种状态通过用户传入的reduceFunction，每次调用add方法添加值时，会调用reduceFunction，最后合并到一个单一的状态值</td>
</tr>
<tr>
<td>AggregatingState&lt;IN, OUT&gt;</td>
<td>存储一个值</td>
<td>AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;</td>
<td>AggregatingState&lt;IN, OUT&gt; getAggregatingState(AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;)</td>
<td>添加数据：add(IN)</td>
<td>聚合State，与ReducingState不同的是，这里的聚合类型可以是不同的元素类型。每次添加值时，会调用AggregateFunction函数计算聚合结果</td>
</tr>
<tr>
<td>MapState&lt;UK, UV&gt;</td>
<td>Map</td>
<td>MapStateDescriptor&lt;UK,UV&gt;</td>
<td>MapState&lt;UK, UV&gt; getMapState(MapStateDescriptor&lt;UK, UV&gt;)</td>
<td>添加：put(UK,UV)/putAll(UK,UV);<br>获取：UV get(UK);<br>遍历：Iterable&lt;Map.Entry&gt; entries()/Iterator&lt;Map.Entry&gt; iterator();</td>
<td>key-value结构数据</td>
</tr>
</tbody>
</table>
<h1 id="keyedstate使用">KeyedState使用</h1>
<p>##KeyedStream<br>
KeyedState只能应用于KeyedStream，如果你想在DataStream上使用Keyed State，你需要首先指定<strong>Key</strong>，Key用于State（也用于流记录本身）的分区。<br>
###指定Key的方式<br>
DataStream的keyBy()方法用于指定Key，并将DataStream转换为KeyedStream。它有如下几种重载方法，官方</p>
<blockquote>
<p>KeySelector</p>
<blockquote>
<p>KeyedStream&lt;T, K&gt; keyBy(KeySelector&lt;T, K&gt; key)<br>
通过实现KeySelector Function中的getKey()方法，自由指定Key的提取<br>
Tuple Keys<br>
KeyedStream&lt;T, Tuple&gt; keyBy(int... fields)<br>
应用于数据类型为简单Tuple类型，通过Tuple下表索引指定Key，当指定多个时为组合键<br>
Expression Keys<br>
KeyedStream&lt;T, Tuple&gt; keyBy(String... fields)<br>
应用于复杂的Tuple类型或POJO类型，对于POJO类型，String参数用于指定字段名</p>
</blockquote>
</blockquote>
<p>Flink的数据模型并不是基于键值对的。因此，KeyedStream并不会将物理上将数据处理为键何值。Key是“虚拟的”：它被定义为在实际数据上用于指导分组操作的函数。</p>
<p>KeyedState保存在StateBackend中</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink State 之 Operator State 应用]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zhi-operator-state-ying-yong/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zhi-operator-state-ying-yong/">
        </link>
        <updated>2020-12-29T12:34:38.000Z</updated>
        <summary type="html"><![CDATA[<p>上文已经说到：Flink中，根据数据集是否根据Key进行分区，将状态分为Keyde State和Operator State两种类型。本文主要关注Operator State以及Operator State相关应用。</p>
]]></summary>
        <content type="html"><![CDATA[<p>上文已经说到：Flink中，根据数据集是否根据Key进行分区，将状态分为Keyde State和Operator State两种类型。本文主要关注Operator State以及Operator State相关应用。</p>
<!-- more -->  
<h1 id="operator-state">Operator State</h1>
<p>Operator State，也称作non-keyed State。每一个Operator State与一个并行的Operator实例绑定，每个Operator实例中都持有所有数据元素的一部分状态。<br>
在典型的Flink有状态应用中，并不需要用到Operator State。它主要是作为一种特殊类型的状态，应用于Source/Sink的实现，以及在没有键进行状态分区的场景。</p>
<h2 id="支持的数据类型">支持的数据类型</h2>
<p>目前Operator State只支持使用<strong>ListState</strong></p>
<h2 id="重分布机制">重分布机制</h2>
<p>当并行度改变时，Operator State接口支持在并行的操作实例之间重分布State，并且支持多种重分布方案：</p>
<ul>
<li>均匀重分布：每一个并行Operator都返回一个状态列表（List）。整个状态空间逻辑上就是所有状态列表的并集。在恢复/重分布阶段，整个状态列表根据并行操作数目均分为子状态列表。每一个并行操作分配一个子状态列表，子状态列表可能为空，也可能包含一个或多个元素。</li>
<li>合并重分布：这种方式将状态的划分交给用户，与均匀重分布方式相比具有更好的灵活性。在恢复/重分布阶段，每一个并行操作都获得了完整的一份状态列表。如果状态基数很大，不建议使用这种方式。因为Checkpoint 元数据会存储每个列表项的偏移量，这可能导致RPC帧大小或内存不足错误。</li>
</ul>
<h1 id="operator-state-应用">Operator State 应用</h1>
<h2 id="如何初始化一个状态state">如何初始化一个状态(State)</h2>
<p>在Flink中，使用状态描述<strong>StateDescriptor</strong>来初始化State，它包含了State的名称以及保存的State值的类型信息</p>
<pre><code class="language-java">ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =
    new ListStateDescriptor&lt;&gt;(
        &quot;buffered-elements&quot;,
        TypeInformation.of(new TypeHint&lt;Tuple2&lt;String,Integer&gt;&gt;() {}));
</code></pre>
<p>上面的代码片段中定义了一个State名称为：buffered-elements，State值类型为：Tuple2&lt;String,Integer&gt; 的状态描述<br>
##CheckpointedFunction<br>
要使用Operator State，有状态的函数需要实现<strong>CheckpointedFunction</strong>接口，该接口需要实现两个方法：</p>
<pre><code class="language-java">void snapshotState(FunctionSnapshotContext context) throws Exception;
void initializeState(FunctionInitializationContext context) throws Exception;
</code></pre>
<p>无论什么时候执行checkpoint，都会调用snapshotState()方法。因此该方法主要定义状态的快照保存逻辑；相应地，每当用户定义的函数被初始化时（无论是函数首次初始化，还是函数实际上从更早一个检查点恢复），都会调用initializeState()方法。因此，initializeState()不仅是不同类型状态初始化的地方，而且也包含了状态恢复的逻辑。</p>
<h2 id="sinkfunction-sample">SinkFunction Sample</h2>
<pre><code class="language-java">public class BufferingSink implements SinkFunction&lt;Tuple2&lt;String, Integer&gt;&gt;,            CheckpointedFunction {

    private final int threshold;

    private transient ListState&lt;Tuple2&lt;String, Integer&gt;&gt; checkpointedState;

    private List&lt;Tuple2&lt;String, Integer&gt;&gt; bufferedElements;

    public BufferingSink(int threshold) {
        this.threshold = threshold;
        this.bufferedElements = new ArrayList&lt;&gt;();
    }

    @Override
    public void invoke(Tuple2&lt;String, Integer&gt; value, Context contex) throws Exception {
        bufferedElements.add(value);
        if (bufferedElements.size() == threshold) {
            for (Tuple2&lt;String, Integer&gt; element: bufferedElements) {
                // send it to the sink
            }
            bufferedElements.clear();
        }
    }

    @Override
    public void snapshotState(FunctionSnapshotContext context) throws Exception {
        checkpointedState.clear();
        for (Tuple2&lt;String, Integer&gt; element : bufferedElements) {
            checkpointedState.add(element);
        }
    }

    @Override
    public void initializeState(FunctionInitializationContext context) throws Exception {
        ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =
            new ListStateDescriptor&lt;&gt;(
                &quot;buffered-elements&quot;,
                TypeInformation.of(new TypeHint&lt;Tuple2&lt;String, Integer&gt;&gt;() {}));

        checkpointedState = context.getOperatorStateStore().getListState(descriptor);

        if (context.isRestored()) {
            for (Tuple2&lt;String, Integer&gt; element : checkpointedState.get()) {
                bufferedElements.add(element);
            }
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink State 之总体介绍]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zong-ti-jie-shao/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zong-ti-jie-shao/">
        </link>
        <updated>2020-12-29T08:09:21.000Z</updated>
        <summary type="html"><![CDATA[<p>本文主要对Flink State进行整体介绍，包括有状态的流式计算框架Flink与传统流式计算框架的区别，Flink State类型划分，State存储与管理以及动态扩容。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文主要对Flink State进行整体介绍，包括有状态的流式计算框架Flink与传统流式计算框架的区别，Flink State类型划分，State存储与管理以及动态扩容。</p>
<!-- more -->
<h1 id="一-有状态流计算介绍">一、有状态流计算介绍</h1>
<h2 id="什么是有状态的计算">什么是有状态的计算</h2>
<p>计算任务的结果不仅仅依赖于输入，还依赖于它的当前状态。比如，很常见的业务场景wordCount，在计算的过程中要不断地把输入累加到count上去，那么<strong>这里的count就是一个state</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609229474736.jpg" alt="" loading="lazy"><br>
Flink基于用户定义代码对到来的数据进行转换操作，处理过程中不仅依赖用户定义算子，还会涉及State数据的读写操作。这些State数据会存储在本地的State backend中，在Checkpoint的时候持久化到配置的Checkpoint 目录</p>
<h2 id="传统流式框架">传统流式框架</h2>
<p>在之前的实时计算框架—Spark进行流式数据处理过程中，流式计算通过将源源不断的数据切分为一个个很小的时间间隔批块，然后针对每一个微批块进行数据计算。它并不是真正意义上的流式处理。每一个微批，只需要保存最终的计算结果，因此，它对于State的需求还是比较小的。</p>
<p>实际上，流式计算对State的要求是非常高的。因为流系统中输入是一个无限制的流，需要保证很长一段时间持续不间断运行，这个过程中就需要很好地将状态数据管理起来。传统的流式计算框架缺乏对State的有效支持：</p>
<ul>
<li>状态数据的存储和访问</li>
<li>状态数据的备份和恢复</li>
<li>状态数据的划分和动态扩容</li>
</ul>
<h2 id="flink提供了丰富的状态访问和高效的容错机制">Flink提供了丰富的状态访问和高效的容错机制</h2>
<ul>
<li>多种数据类型：Value、List、Map、Reducing、Folding、Aggregating</li>
<li>多种划分方式： Keyed State、Operator State</li>
<li>多种存储格式： MemoryStateBackend、FsStateBackend、RocksDBStateBackend</li>
<li>高效的备份和恢复：提供ExactlyOnce保证、增量及异步备份本地恢复</li>
</ul>
<h1 id="二-flink-state-类别">二、Flink State 类别</h1>
<p>Flink中，State按照是否有Key划分为Keyed State和Operator State</p>
<h2 id="keyed-state">Keyed State</h2>
<p><strong>Keyed State</strong>在Keyed Stream中使用。状态是跟特定的Key绑定的，即Keyed Stream流上的每一个Key对应一个State对象。</p>
<h2 id="operator-state">Operator State</h2>
<p><strong>Operator State</strong>(non-keyed state)跟一个特定操作的并行实例绑定，整个操作只对应一个State。典型的Operator State应用场景就是Kafka Source Connector，kafka consumer的每一个并行实例都维护了topic partition与offsets的映射关系作为它的Operator State。<br>
<strong>Broadcast State</strong>是一个特殊的Operator State。它的引入是为了支持一个流的记录需要被广播到下游的所有并行任务的场景，在这种场景中，它们被用来在所有的并行任务中维护相同的状态。然后，可以在处理第二个流的记录时访问这个状态。broadcast state与operator state的其他区别：</p>
<ol>
<li>状态的数据类型为Map格式</li>
<li>它仅在具有两个输入流的特定操作上可用，一个输入流为broadcasted stream ，一个输入流为non-broadcasted</li>
<li>这些操作可以定义多个具有不同名称的broadcast state</li>
</ol>
<p><strong>详细对比：</strong></p>
<table>
<thead>
<tr>
<th>对比维度</th>
<th>Keyed State</th>
<th>Operator State</th>
</tr>
</thead>
<tbody>
<tr>
<td>使用场景</td>
<td>只能用于KeyedStream上的算子</td>
<td>可以用于所有的算子，常用于Source，例如FlinkKafkaConsumer</td>
</tr>
<tr>
<td>应用</td>
<td>通过RuntimeContext访问，操作函数需要实现RichFunction接口</td>
<td>实现CheckpointedFunction或ListCheckpointed接口</td>
</tr>
<tr>
<td>是否需要手动声明快照(snapshot)和恢复（restore)方法</td>
<td>由backend自行实现，对用户透明</td>
<td>需要手动实现snapshot和restore方法</td>
</tr>
<tr>
<td>支持数据接口</td>
<td>包括：ValueState、ListState、ReducingState、AggregatingState、MapState</td>
<td>ListState。特别说明：Broadcast State 是MapState类型</td>
</tr>
<tr>
<td>是否存在当前处理的 key（current key）</td>
<td>keyed state的value总是与一个current key对应。一个Operator实例处理多个key，访问相应的多个State</td>
<td>无当前key概念。一个Operator实例对应一个State</td>
</tr>
<tr>
<td>并发改变时State重分布</td>
<td>基于Key-Group，State随着Key在实例间迁移</td>
<td>并发改变时，有多种重新分配方式可选：均匀分配；合并后每个实例都得到全量状态</td>
</tr>
<tr>
<td>存储对象是否 on heap</td>
<td>keyed state backend 有on-heap和off-heap(RocksDB)的多种实现</td>
<td>目前operator state backend仅有一种on-heap的实现</td>
</tr>
<tr>
<td>状态数据大小【这只是个经验判断，不是绝对的判断区分标准】</td>
<td>一般而言，Keyed state规模的相对比较大的</td>
<td>一般而言，我们认为operator state的数据规模是比较小的</td>
</tr>
</tbody>
</table>
<h1 id="三-flink-state存储和管理">三、Flink State存储和管理</h1>
<h2 id="state-backend-分类">State Backend 分类</h2>
<p>State在内部如何表述，checkpoint时，State如何以及在哪里进行持久化，依赖于选择的State Backend。Flink默认捆绑了三类State Backends：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。在未配置的情况下，系统将默认使用MemoryStateBackend。</p>
<p><strong>详细区别：</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609232674288.jpg" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>State Backend 类型</th>
<th>State存储</th>
<th>Checkpoint时存储</th>
<th>快照方式</th>
<th>是否支持增量Checkpoint</th>
<th>限制</th>
<th>使用场景</th>
<th>推荐设置</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>MemoryStateBackend</td>
<td>TaskManager内存</td>
<td>JobManager内存</td>
<td>默认异步方式</td>
<td>否</td>
<td>1. 单个State默认限制为5MB，当然这个值可以在创建state backend时调整<br>2. 但是Max State最大不能超过akka frame的size (默认10M)<br>3. 聚合的State总大小要小于JobManager内存大小</td>
<td>1. 本地开发和debugging<br>2. 需要存储很少量状态的作业<br>3. 不推荐生产场景</td>
<td>将managed memory设置为0.确保最大量地使用分配内存给用户作业</td>
<td>1. State数据作为Java堆对象在本地（TaskManager）存储<br>2. 在Checkpoint时，state backend会快照状态数据，作为checkpoint确认消息的一部分发送给JobManager。在JobManager上，状态数据也是在Java 堆上存储的</td>
</tr>
<tr>
<td>FsStateBackend</td>
<td>TaskManager内存</td>
<td>外部文件系统（本地目录或HDFS目录）</td>
<td>默认异步方式</td>
<td>否</td>
<td>1.单Taskmanager上的State总量不超过它的内存<br>2.总大小不超过配置的文件系统容量</td>
<td>1.大状态作业，长窗口，大key/value 状态<br>2.高可用设置<br>3.生产场景</td>
<td>同上</td>
<td>1.在TaskManager的内存中，存储正在使用的State数据<br>2. Checkpointing时，state backend将状态快照写文件到配置文件系统和目录中。最小化的元数据存储在JobManager的内存【状态数据存储的路径】（高可用模式，存储元数据在元数据checkpoint路径）</td>
</tr>
<tr>
<td>RocksDBStateBackend</td>
<td>TaskManager上的KV数据库(RocksDB)【实际使用内存+磁盘】</td>
<td>外部文件系统（本地目录或HDFS目录）</td>
<td>总是异步</td>
<td>是</td>
<td>1.单TaskManager上的State不超过它的内存+磁盘<br>2.单Key最大2G<br>3.总大小不超过配置的文件系统容量</td>
<td>1.大状态作业，长窗口，大key/value 状态<br>2.高可用设置<br>3.生产场景</td>
<td></td>
<td>1.RocksDBStateBackend在RocksDB数据库中保存正在使用的状态数据，默认存储在TaskManager的数据目录<br>2.在checkpointing时，整个RocksDB数据库将被快照到配置的文件系统或目录。最小化的元数据存储在JobManager的内存中（高可用模式，存储在元数据checkpoint目录）</td>
</tr>
</tbody>
</table>
<p><strong>关于RocksDBStateBackend的特别说明：</strong></p>
<ol>
<li>这种方式可以维持的状态量只受限于可用的磁盘空间。与FsStateBackend将state存储在内存相比，这种方式允许保留更大的state</li>
<li>但是，这也意味着，可以获取的最大吞吐量将比FsStateBackend方式的低</li>
<li>所有对backend的read/write都需要通过序列化/反序列化，以存储/获取状态对象。这种方式与基于堆的存储方式代价更高</li>
</ol>
<h2 id="state-backend配置">State Backend配置</h2>
<ul>
<li>配置默认State Backend</li>
</ul>
<blockquote>
<p>flink-conf.yml<br>
state.backend: 【可能的取值：jobmanager(MemoryStateBackend)、fileSystem(FsStateBackend)、rocksdb(RocksDBStateBackend)、或者实现了state backend factory StateBackendFactory的全限定类名（org.apache.flink.contrib.streaming.state.RocksDBStateBackendFactory）】<br>
state.checkpoints.dir:定义backend写快照数据和元数据文件的目录</p>
</blockquote>
<ul>
<li>per-job 设置State Backend</li>
</ul>
<blockquote>
<p>StreamExecutionEnvironment</p>
</blockquote>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setStateBackend(new FsStateBackend(&quot;hdfs://namenode:40010/flink/checkpoints&quot;));
</code></pre>
<h1 id="四-flink-state-划分和动态扩容">四、Flink State 划分和动态扩容</h1>
<h2 id="state-划分">State 划分</h2>
<ul>
<li>对于Operator State类型，每一个并行的Operator实例对应一个State</li>
<li>对于Keyed State类型，每一个Current Key对应一个State</li>
</ul>
<h2 id="state-动态扩容">State 动态扩容</h2>
<p><strong>Operator State类型</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609232700062.jpg" alt="" loading="lazy"></p>
<ul>
<li>ListState：并发度改变的时候，会将并发实例上的ListState都合并到一个新的List，然后均匀分配到变更后的并发Task上</li>
<li>UnionListState：每一个并发Task都会拿到全量的ListState</li>
<li>BroadcastState：每个并发Task上的State都是完全一致的，因此，当增大并发度时，只需要Copy一份State到新Task即可</li>
</ul>
<p><strong>Keyed State类型</strong><br>
在并行度改变时，如何重分布KeyedState数据，最直观的做法就是计算每个Key的Hash值，并基于并行度parallelism取余。下图为当并行度改变时，基于Hash取余算法的State数据重分布情况：<br>
<img src="https://wangyemao-github.github.io/post-images/1609232708709.png" alt="" loading="lazy"></p>
<p>hash取余重分布算法存在的问题：之前在各个Task上维护好的State数据会根据新的并行度重新组织，State数据在各个Task之间传输。这对于KeyedState数据较大时，数据重新组织的代价会很高。</p>
<p>为了规避上述问题，Flink基于Key-Group(KeyedState的最小组织单位)组织、分配KeyedState。具体的映射关系为</p>
<pre><code class="language-java">public static int assignToKeyGroup(Object key, int maxParallelism) {
   return computeKeyGroupForKeyHash(key.hashCode(), maxParallelism);
}
public static int computeKeyGroupForKeyHash(int keyHash, int maxParallelism) {
   return MathUtils.murmurHash(keyHash) % maxParallelism;
}
</code></pre>
<p>也就是说，Key-Group数量取决于最大并行度（MaxParallism），只要最大并行度不变，同一个key归属的Key-Group是不会变更的。另外，此处在HashCode的基础上又调用murmurHash方法是为了保证尽量散列。</p>
<p>在对Key划分Key-Group之后，MaxParallism个Key-Group 基于KeyGroupRange分配到parallelism个并行Task中，每一个并行Task持有1个KeyGroupRange，具体计算方法：</p>
<pre><code>public static KeyGroupRange computeKeyGroupRangeForOperatorIndex(
   int maxParallelism,
   int parallelism,
   int operatorIndex) {
   int start = ((operatorIndex * maxParallelism + parallelism - 1) / parallelism);
   int end = ((operatorIndex + 1) * maxParallelism - 1) / parallelism;
   return new KeyGroupRange(start, end);
}
</code></pre>
<p><strong>以一个具体的实例说明：</strong><br>
对于一个Key 空间=[0,1,2,3,4,5,6,7,8,9] 的数据，MaxParallelism=5，并行度Parallelism由2扩大到3的过程中， 各个并行Task的Key-Group重分布情况为：<br>
<img src="https://wangyemao-github.github.io/post-images/1609232723011.png" alt="" loading="lazy"><br>
<strong>总结：</strong></p>
<ol>
<li>只要MaxParallelism不变，整个Key空间的Key-Group划分情况是不会变更的</li>
<li>当并行度变更时，基于Key-Group，将Key-Group重新分配到并行Task中，并且这种重新分配不是一个Shuffle，Key-Group归属的并行Task的变更很小。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://wangyemao-github.github.io/post/hello-gridea/</id>
        <link href="https://wangyemao-github.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>