<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wangyemao-github.github.io</id>
    <title>Gridea</title>
    <updated>2021-01-15T11:22:06.486Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wangyemao-github.github.io"/>
    <link rel="self" href="https://wangyemao-github.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://wangyemao-github.github.io/images/avatar.png</logo>
    <icon>https://wangyemao-github.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Flink Time]]></title>
        <id>https://wangyemao-github.github.io/post/flink-time/</id>
        <link href="https://wangyemao-github.github.io/post/flink-time/">
        </link>
        <updated>2021-01-13T01:47:03.000Z</updated>
        <summary type="html"><![CDATA[<p>在Flink中有状态流式处理中，Time承担着一定的作用。比如：进行时间序列的分析，基于特定时间段的聚合（window操作），以及基于发生时间的事件处理等。本文主要讲解Flink中时间概念，及针对不同的时间特性，Flink中提取时间戳及生成水印的策略</p>
]]></summary>
        <content type="html"><![CDATA[<p>在Flink中有状态流式处理中，Time承担着一定的作用。比如：进行时间序列的分析，基于特定时间段的聚合（window操作），以及基于发生时间的事件处理等。本文主要讲解Flink中时间概念，及针对不同的时间特性，Flink中提取时间戳及生成水印的策略</p>
<!-- more -->
<h1 id="flink-time">Flink Time</h1>
<h2 id="time-notition">Time notition</h2>
<p>Flink流程序中支持多种不同的时间概念，包括：Processing Time，Event Time 和 Ingestion Time。下面为官网的说明图及解释：</p>
<figure data-type="image" tabindex="1"><img src="https://wangyemao-github.github.io/post-images/1610709415381.png" alt="" loading="lazy"></figure>
<ul>
<li>Processing Time<br>
Processing Time 是事件在执行相关操作时，所在机器的系统时间。当流程序在Processing Time上运行时，所有基于时间(比如windows操作)都将使用当时机器的系统时间。每小时处理时间窗口将包括在系统时钟指示整小时之间到达特定操作的所有记录。例如：如果应用程序在上午9:15开始运行，那第一个小时Processing Time 窗口将包括从上午9:15到上午10:00的事件；下一个窗口包含从上午10:00到11:00的事件。<br>
Processing Time是最简单的时间概念。它不需要流和机器之间的协调，并且提供了最好的性能及最低的延迟。但是，由于会受到事件到达系统的速度，以及事件在系统内操作流动速度的影响，在分布式和异步环境下，基于Processing Time的流程序不能提供确定性的结果</li>
<li>Event Time<br>
Event Time 是指事件的发生时间，通常事件到达Flink之前本身就携带了这个时间。在基于事件时间的流程序中，时间取决于数据，跟机器系统时间无关。使用Event Time，需要指定如何提取事件时间，以及如何生成Event Time watermark。<br>
在理想情况下，无论事件什么时候到达，无论事件如何乱序到达，基于Event Time的流程序总会得到一致且确定的结果。但事实上，除非事件按照既定的顺序到达，否则流程序会因为需要等待一些无序的事件而产生延迟。由于只能等待一段有限的时间，因此很难保障基于Event Time的流程序总是得到一致且确定性的结果。</li>
<li>Ingestion Time<br>
Ingestion Time 是事件进入Flink 的时间。在源操作处，每个事件将当前机器的系统时间作为时间戳，后续的所有基于时间的操作(window操作)都将使用这个时间戳。<br>
<strong>与另外两个时间的对比</strong></li>
</ul>
<ol>
<li>与Event Time 相比，Ingestion Time 无法处理任何无序或延迟事件，因为时间都是在进入Flink源时，统一分配的机器系统时间，事件的顺序已被重新定义；但是使用Ingestion Time的流程序由Flink自动分配时间戳，自动生成水印，不需要用户代码额外指定</li>
<li>与Processing Time 相比，Ingestion Time稍微更贵一些，但结果更可预测。</li>
</ol>
<h2 id="设定时间特性">设定时间特性</h2>
<p>下面的代码片段为在Flink中设定不同时间特性的：</p>
<pre><code class="language-java">final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
//设置时间特性为Processing Time
env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime); 
//设置时间特性为Ingestion Time
env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime);
//设置时间特性为Event Time
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
</code></pre>
<h1 id="watermarks">WaterMarks</h1>
<p>支持Event Time的流程序中，由于各种原因，不可能完全保证事件都按照既定的顺序到达，通常事件达到都是无序的并且存在延迟。那基于时间的操作，比如window操作就需要一种方法来衡量时间的进度。在Flink中这种衡量Event Time进度的机制就称作<strong>WaterMarks</strong>。<br>
在Flink中，watermarks作为数据流的一部分在流程序中流动，并携带了一个时间戳<strong>t</strong>。<strong>watermark(t)<strong>表明所有时间戳&lt;=t的事件都已经到达。<br>
下图为有序事件流和无序事件流中watermark：<br>
<img src="https://wangyemao-github.github.io/post-images/1610506420248.png" alt="" loading="lazy"><br>
<img src="https://wangyemao-github.github.io/post-images/1610506426262.png" alt="" loading="lazy"><br>
在有序事件流中，watermark只是事件流中简单地周期性标记。<br>
在无序事件流中，watermark充当着很重要的作用。一旦</strong>watermark(t)<strong>到达某个操作，操作将使用watermark携带的时间戳更新内部</strong>event time clock</strong>。当满足特定条件时触发计算<br>
设置不同的时间特性，watermark是否需要用户程序设定如下表：</p>
<table>
<thead>
<tr>
<th></th>
<th>Processing Time</th>
<th>Event Time</th>
<th>Ingestion Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>watermark</td>
<td>不需要</td>
<td>用户程序指定</td>
<td>系统自动生成</td>
</tr>
</tbody>
</table>
<h1 id="time-characteristic-watermark-生成-源码分析">Time Characteristic &amp; watermark 生成 源码分析</h1>
<p>在Flink流程序中，当指定时间特性为Ingestion Time之后，在源操作处，对于到来的每个事件，将使用当时的机器系统时间作为事件时间戳并自动生成水印。<br>
在Flink中，源操作处如何发送数据（提取时间戳）、如何生成水印都是由<strong>SourceFunction.SourceContext</strong>接口定义的</p>
<pre><code class="language-java">public interface SourceFunction&lt;T&gt; extends Function, Serializable {
    /**
     *  Interface that source functions use to emit elements, and possibly watermarks   
     */
    interface SourceContext&lt;T&gt; {
        //Emits one element from the source, without attaching a timestamp
        void collect(T element);
        // Emits one element from the source, and attaches the given timestamp
        void collectWithTimestamp(T element, long timestamp);
        //Emits the given {@link Watermark}
        void emitWatermark(Watermark mark);
    }
}
</code></pre>
<p>针对不同的时间特性(Time Characteristic)，StreamSourceContext定义了三种不同的SourceContext实现。NonTimeStampContext、AutomaticWatermarkContext、ManualWatermarkContext。其中后两者都继承自WatermarkContext。</p>
<pre><code class="language-java">//Source contexts for various stream time characteristics
public class StreamSourceContexts {
    /**
     * Depending on the {@link TimeCharacteristic}, this method will return
     * the adequate {@link    org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext}
    **/ 
    public static &lt;OUT&gt; SourceFunction.SourceContext&lt;OUT&gt; getSourceContext(
			TimeCharacteristic timeCharacteristic,
			ProcessingTimeService processingTimeService,
			Object checkpointLock,
			StreamStatusMaintainer streamStatusMaintainer,
			Output&lt;StreamRecord&lt;OUT&gt;&gt; output,
			long watermarkInterval,
			long idleTimeout){
                final SourceFunction.SourceContext&lt;OUT&gt; ctx;
                switch (timeCharacteristic) {
			case EventTime:
				ctx = new ManualWatermarkContext&lt;&gt;(
					output,
					processingTimeService,
					checkpointLock,
					streamStatusMaintainer,
					idleTimeout);
				break;
			case IngestionTime:
				ctx = new AutomaticWatermarkContext&lt;&gt;(
					output,
					watermarkInterval,
					processingTimeService,
					checkpointLock,
					streamStatusMaintainer,
					idleTimeout);
				break;
			case ProcessingTime:
				ctx = new NonTimestampContext&lt;&gt;(checkpointLock, output);
				break;
			default:
				throw new IllegalArgumentException(String.valueOf(timeCharacteristic));
            }
}
</code></pre>
<p>从上面的代码片段中可见，不同的时间特性（TimeCharacteristic）会实现不同SourceContext，其对应关系为：ProcessTime对应NonTimestampContext；EventTime对应ManualWatermarkContext；IngestionTime对应AutomaticWatermarkContext。</p>
<h2 id="processingtime-时间戳-和水印生成">ProcessingTime &amp; 时间戳 和水印生成</h2>
<p>对于指定Processing Time 情况，时间戳与水印如何生成，具体看<strong>NonTimestampContext</strong>实现：</p>
<pre><code class="language-java">/**
 *  A source context that attached {@code -1} as a timestamp to all records,   *   and that does not forward watermarks
 **/
private static class NonTimestampContext&lt;T&gt; implements SourceFunction.SourceContext&lt;T&gt;{
    public void collect(T element) {
			synchronized (lock) {
				output.collect(reuse.replace(element));
			}
	}
    public void collectWithTimestamp(T element, long timestamp) {
			// ignore the timestamp
			collect(element);
	}
    public void emitWatermark(Watermark mark) {
			// do nothing
	}
}
</code></pre>
<p>从上面代码可见，NonTimestampContext没有为事件生成时间戳，对于传入时间戳的情况，也会将时间戳忽略。另外，发送水印方法为空实现，即不会向下游发送水印(Watermark)。<br>
事实上，对于使用ProcessingTime情况，生成时间戳和向下游发送水印并没有实际意义。因为，对于时间相关的操作(window类操作)，各个计算节点会根据机器的系统时间定义触发器，触发计算，而不是根据watermark来触发。</p>
<h2 id="ingestiontime-时间戳-和水印生成">IngestionTime &amp; 时间戳 和水印生成</h2>
<p>对于IngestionTime情况，时间戳生成及水印生成具体看<strong>AutomaticWatermarkContext</strong>实现。另外前面说到AutomaticWatermarkContext和ManualWatermarkContext都继承自WatermarkContext。此处首先会大概说明下<strong>WatermarkContext</strong>具体实现了什么功能：<br>
WatermarkContext定义了与watermark相关的行为(因为不是本文的重点，此处简要说明)：</p>
<ul>
<li>负责管理当前的StreamStatus，确保StreamStatus向下游传递；</li>
<li>负责空闲监测逻辑，当超过设定的时间间隔还没有收到数据或者watermark时，会认为Task处于空闲状态。空闲监测逻辑是很有意义上的：如果某个源操作Task标志为空闲状态，后续的Checkpoint中不需要再等待该Task barrier对齐，不需要耗费资源或时间等待</li>
</ul>
<h3 id="如何生成事件时间戳">如何生成事件时间戳</h3>
<p>回到AutomaticWatermarkContext，我们看下在IngestionTime情况，系统是如何自动赋值时间戳，如何自动生成watermark，首先看下时间戳：</p>
<pre><code class="language-java">protected void processAndCollect(T element) {
			lastRecordTime = this.timeService.getCurrentProcessingTime();
			output.collect(reuse.replace(element, lastRecordTime));

			// this is to avoid lock contention in the lockingObject by
			// sending the watermark before the firing of the watermark
			// emission task.
			if (lastRecordTime &gt; nextWatermarkTime) {
				// in case we jumped some watermarks, recompute the next watermark time
				final long watermarkTime = lastRecordTime - (lastRecordTime % watermarkInterval);
				nextWatermarkTime = watermarkTime + watermarkInterval;
				output.emitWatermark(new Watermark(watermarkTime));

				// we do not need to register another timer here
				// because the emitting task will do so.
			}
	}

    protected void processAndCollectWithTimestamp(T element, long timestamp) {
			processAndCollect(element);
	}
</code></pre>
<p>两个向下游发送数据的方法最终都是执行都是上面的processAndCollect(element)方法。对于每一条数据记录，会取当前的ProcessingTime(机器系统时间)作为事件时间戳，然后发送到下游。</p>
<h3 id="如何生成水印">如何生成水印</h3>
<p>在AutomaticWatermarkContext的构造方法中会初始化两个重要的属性：</p>
<pre><code class="language-java">private AutomaticWatermarkContext(
				final Output&lt;StreamRecord&lt;T&gt;&gt; output,
				final long watermarkInterval,
				final ProcessingTimeService timeService,
				final Object checkpointLock,
				final StreamStatusMaintainer streamStatusMaintainer,
				final long idleTimeout) {
			super(timeService, checkpointLock, streamStatusMaintainer, idleTimeout);
            
			this.watermarkInterval = watermarkInterval;
			long now = this.timeService.getCurrentProcessingTime();
			this.nextWatermarkTimer = this.timeService.registerTimer(now + watermarkInterval,
				new WatermarkEmittingTask(this.timeService, checkpointLock, output));
		}
</code></pre>
<p>第一个属性是<strong>watermarkInterval</strong>，它指定了水印(watermark)的生成周期，具体的取值为：</p>
<pre><code class="language-java">watermarkInterval = getRuntimeContext().getExecutionConfig().getAutoWatermarkInterval(); 
</code></pre>
<p>默认情况下，生成周期为200ms，当然可以调用ExecutionConfig#setAutoWatermarkInterval（long interval）重新指定<br>
第二个重要的属性是<strong>nextWatermarkTimer</strong>，它是一个ProcessingTimeService定时器，当<strong>ProceingTime = now + watermarkInterval</strong>时，也就是间隔<strong>watermarkInterval</strong>时间之后，会触发回调<strong>WatermarkEmittingTask#onProcessingTime</strong>方法，下面为从WatermarkEmittingTask中摘取的重要代码片段：</p>
<pre><code class="language-java"> private class WatermarkEmittingTask implements ProcessingTimeCallback{

     public void onProcessingTime(long timestamp) {
				final long currentTime = timeService.getCurrentProcessingTime();
                synchronized (lock) {
					// we should continue to automatically emit watermarks if we are active
					if (streamStatusMaintainer.getStreamStatus().isActive()) {
						if (idleTimeout != -1 &amp;&amp; currentTime - lastRecordTime &gt; idleTimeout) {
						} else if (currentTime &gt; nextWatermarkTime) {
							// align the watermarks across all machines. this will ensure that we don't have watermarks that creep along at different intervals because the machine clocks are out of sync 
							final long watermarkTime = currentTime - (currentTime % watermarkInterval);
							output.emitWatermark(new Watermark(watermarkTime));
							nextWatermarkTime = watermarkTime + watermarkInterval;
						}
					}
				}
				long nextWatermark = currentTime + watermarkInterval;
				nextWatermarkTimer = this.timeService.registerTimer(
						nextWatermark, new WatermarkEmittingTask(this.timeService, lock, output));
			}
 }
</code></pre>
<p>上面代码片段中可以看到：（1）在对水印时间进行矫正之后，会将水印时间发送到下游；（2）注册下一次触发时间。也就是说，在<strong>AutomaticWatermarkContext</strong>中使用一个定时器，每当注册触发时间到来时，会自动向下游发送水印，并且会持续地自动注册下一次触发时间。<strong>触发时间为：（作业启动时刻+watermark周期*n）</strong></p>
<h2 id="event-time-时间戳和水印生成">Event Time &amp; 时间戳和水印生成</h2>
<p>最后，我们看一下基于Event Time的流程序，在源操作处，是如何处理事件时间戳和水印生成的。具体的实现在<strong>ManualWatermarkContext</strong>：</p>
<pre><code class="language-java">private static class ManualWatermarkContext&lt;T&gt; extends WatermarkContext&lt;T&gt;{
    protected void processAndCollectWithTimestamp(T element, long timestamp) {
			output.collect(reuse.replace(element, timestamp));
	}
    protected void processAndEmitWatermark(Watermark mark) {
			output.emitWatermark(mark);
	}
    protected boolean allowWatermark(Watermark mark) {
			return true;
	}
}
</code></pre>
<p>从上面代码片段中可以看出：在使用Event Time的情况下，ManualWatermarkContext不会额外生成时间戳，也不会生成watermark。对于数据和水印都只做透传。<br>
那么，这种情况下透传的时间戳和水印是从哪里来的呢？答案就是UDF(User Defined Function)。具体可以去看下<strong>StreamSource#run</strong>方法：在run方法中根据设置的时间特性创建StreamSourceContexts 之后，会将创建的方法：在run方法中根据设置的时间特性创建StreamSourceContexts传给userFunction：</p>
<pre><code class="language-java">this.ctx = StreamSourceContexts.getSourceContext(
			timeCharacteristic,
			getProcessingTimeService(),
			lockingObject,
			streamStatusMaintainer,
			collector,
			watermarkInterval,
			-1);
userFunction.run(ctx);
</code></pre>
<p>时间戳提取及水印的生成在用户定义的SourceFunction中完成之后，到StreamSourceContexts时，只做数据的透传。</p>
<h2 id="flink-kafka-source-时间戳和水印生成">Flink Kafka Source 时间戳和水印生成</h2>
<p>本节以Flink-source-connector中KafkaConsumer 为例，说明在设置不同时间特性情况下，时间戳和水印如何生成。基于Flink1.8版本，kafka-010。<br>
对于消费kafka的每条记录会调用emitRecord()方法发出数据，该方法中会进行时间戳的提取和水印生成：</p>
<pre><code class="language-java">//emit the actual record. this also updates offset state atomically
//and deals with timestamps and watermark generation
protected void emitRecord(
			T record,
			KafkaTopicPartitionState&lt;TopicPartition&gt; partition,
			long offset,
			ConsumerRecord&lt;?, ?&gt; consumerRecord) throws Exception {
		// we attach the Kafka 0.10 timestamp here
		emitRecordWithTimestamp(record, partition, offset, consumerRecord.timestamp());
}
</code></pre>
<p>在emitRecord()方法中调用了emitRecordWithTimestamp()方法，并且传入的时间戳为：consumerRecord.timestamp()。也就是从kafka中消费出来的数据所带的时间戳。具体看下**emitRecordWithTimestamp()**方法：</p>
<pre><code class="language-java">protected void emitRecordWithTimestamp(
			T record, KafkaTopicPartitionState&lt;KPH&gt; partitionState, long offset, long timestamp) throws Exception {
		if (record != null) {
			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {
				// fast path logic, in case there are no watermarks generated in the fetcher  emit the record, using the checkpoint lock to guarantee atomicity of record emission and offset state update
				synchronized (checkpointLock) {
					sourceContext.collectWithTimestamp(record, timestamp);
					partitionState.setOffset(offset);
				}
			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {
				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp);
			} else {
				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp);
			}
		} 
</code></pre>
<p>上面代码中，根据timestampWatermarkMode的不同取值会调用不同的方法发出数据。首先看下<strong>timestampWatermarkMode</strong>取值：</p>
<pre><code class="language-java">if (watermarksPeriodic == null) {
			if (watermarksPunctuated == null) {
				// simple case, no watermarks involved
				timestampWatermarkMode = NO_TIMESTAMPS_WATERMARKS;
			} else {
				timestampWatermarkMode = PUNCTUATED_WATERMARKS;
			}
		} else {
			if (watermarksPunctuated == null) {
				timestampWatermarkMode = PERIODIC_WATERMARKS;
			} else {
				throw new IllegalArgumentException(&quot;Cannot have both periodic and punctuated watermarks&quot;);
			}
}
</code></pre>
<p>在没有设置属性watermarksPeriodic和watermarksPunctuated时，timestampWatermarkMode取值为NO_TIMESTAMPS_WATERMARKS；否则，如果设置了watermarksPunctuated，timestampWatermarkMode的取值为PUNCTUATED_WATERMARKS；否则，如果设置了watermarksPeriodic，则timestampWatermarkMode的取值为PERIODIC_WATERMARKS。</p>
<ol>
<li>对于时间特性(TimeCharacteristic)设置为processing Time 或 Ingestion Time的情况：</li>
</ol>
<blockquote>
<p>这种情况是没有必要设置watermarksPeriodic和watermarksPunctuated属性的。因为，对于Processing Time情况，设置时间戳和水印没有实际意义；而对于Ingestion Time情况，具体会在SourceStreamContext中自动生成。<br>
这种情况下，timestampWatermarkMode取值为NO_TIMESTAMPS_WATERMARKS，直接调用了方法: sourceContext.collectWithTimestamp(record, timestamp)，后续如何提取时间戳，如何生成水印依赖于设置的时间特性，由具体SourceStreamContext实现（前面已经说明，此处不再赘述）。</p>
</blockquote>
<ol start="2">
<li>对于Event Time情况：</li>
</ol>
<blockquote>
<p>对于这种情况，如果想要在源操作处完成时间戳提取以及水印的生成，需要自定义具体AssignerWithPunctuatedWatermarks或AssignerWithPeriodicWatermarks的实现，包括如何提取时间戳，以及如何生成下一个水印。<br>
在FlinkKafkaConsumerBase类中提供了两个方法分别接收用户自定义的AssignerWithPunctuatedWatermarks或AssignerWithPeriodicWatermarks。具体为：</p>
</blockquote>
<pre><code class="language-java">public FlinkKafkaConsumerBase&lt;T&gt; assignTimestampsAndWatermarks(AssignerWithPunctuatedWatermarks&lt;T&gt; assigner) {}

public FlinkKafkaConsumerBase&lt;T&gt; assignTimestampsAndWatermarks(AssignerWithPeriodicWatermarks&lt;T&gt; assigner){}
</code></pre>
<h2 id="基于flink-kafka-consumer的消费实例">基于Flink kafka consumer的消费实例</h2>
<p>下面以一个具体的实例，阐述Flink消费kafka数据时如何在数据源出自定义时间戳提取以及生成水印：</p>
<ol>
<li>kafka producer端<pre><code class="language-java">public class WriteDataToKafka {
 public static void main(String[] args) throws IOException {
     Map&lt;String, String&gt; config = new HashMap&lt;String, String&gt;();
     config.putAll(ReadPropertiesUtils.readConfig(&quot;config.properties&quot;));
     Properties properties = new Properties();
     properties.put(&quot;zookeeper.connect&quot;, config.get(&quot;zookeeper.connect&quot;));
     properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
     properties.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
     properties.put(&quot;bootstrap.servers&quot;, config.get(&quot;metadata.broker.list&quot;));

     try {
         KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String, String&gt;(properties);
         final String[] arr = new String[]{&quot;a&quot;, &quot;b&quot;};
         Timer timer = new Timer();
         timer.schedule(new TimerTask() {
             @Override
             public void run() {
                 for (int i = 0; i &lt; arr.length; i++) {
                     SampleObj sampleObj = new SampleObj();
                     sampleObj.setValue(arr[i]);
                     sampleObj.setOccurTime(System.currentTimeMillis());
                     System.out.println(JSONObject.toJSON(sampleObj).toString());
                     ProducerRecord&lt;String, String&gt; record =
                             new ProducerRecord&lt;String, String&gt;(&quot;test_topic&quot;,
                                     JSONObject.toJSON(sampleObj).toString());
                     kafkaProducer.send(record);
                     kafkaProducer.flush();
                 }
             }
         }, 0L, 1000);
     } catch (Exception e) {
         e.printStackTrace();
     }
 }
</code></pre>
</li>
</ol>
<p>}</p>
<pre><code>每隔1s向kafka 的test_topic中分别发送两条value取值为&quot;a&quot;或&quot;b&quot;的两条数据，数据的时间戳为构造数据时机器的系统时间。
发送数据对应的实体类定义为：
``` java 
public class SampleObj {
 private String value;
 private Long occurTime;}
</code></pre>
<ol start="2">
<li>Flink 端消费数据代码<br>
Flink 应用程序消费test_topic 的数据，每隔10s统计下各个value对应的count数，并打印到控制台。<pre><code class="language-java">public class FlinkKafkaConsumerSample {
        public static void main(String[] args) throws Exception {
     final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
     env.enableCheckpointing(5000);
     //设定时间特性为Event Time
     env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
     Properties props = new Properties();
     props.setProperty(&quot;bootstrap.servers&quot;, &quot;10.154.8.27:9092&quot;);
     props.setProperty(&quot;group.id&quot;, &quot;alarm_consumer_test&quot;);

     FlinkKafkaConsumer010&lt;JSONObject&gt; consumer =
             new FlinkKafkaConsumer010&lt;&gt;(&quot;test_topic&quot;, new JsonFormatDeserializer(), props);
     consumer.assignTimestampsAndWatermarks(new AssignerWithPunctuatedWatermarks&lt;JSONObject&gt;() {

         @Override
         public long extractTimestamp(JSONObject element, long previousElementTimestamp) {
             if (StringUtils.isNotBlank(element.getString(&quot;occurTime&quot;))) {
                 System.out.println(&quot;数据：&quot; + element.getString(&quot;value&quot;) + &quot;:&quot; + timeStamp2Date(element.getLong(&quot;occurTime&quot;)));
                 return Long.valueOf(element.getString(&quot;occurTime&quot;));
             } else return 0L;
         }

         @Nullable
         @Override
         public Watermark checkAndGetNextWatermark(JSONObject lastElement, long extractedTimestamp) {
             if (StringUtils.isNotBlank(lastElement.getString(&quot;occurTime&quot;))) {
                 return new Watermark(Long.valueOf(lastElement.getString(&quot;occurTime&quot;)));
             } else return null;
         }
     });

     env.addSource(consumer)
             .keyBy((KeySelector&lt;JSONObject, String&gt;) value -&gt; value.getString(&quot;value&quot;))
             .timeWindow(Time.seconds(10))
             .process(new ProcessWindowFunction&lt;JSONObject, Tuple3&lt;String, Long, String&gt;, String, TimeWindow&gt;() {
                 @Override
                 public void process(String s, Context context, Iterable&lt;JSONObject&gt; elements, Collector&lt;Tuple3&lt;String, Long, String&gt;&gt; out) throws Exception {
                     System.out.println(&quot;currentProcessTime:&quot; + timeStamp2Date(context.currentProcessingTime()) +
                             &quot;watermark:&quot; + timeStamp2Date(context.currentWatermark()) +
                             &quot;window info,start:&quot; + timeStamp2Date(context.window().getStart()) +
                             &quot;;end:&quot; + timeStamp2Date(context.window().getEnd()));
                     long sum = 0L;
                     long maxTime = Long.MIN_VALUE;
                     for (JSONObject jsonObject : elements) {
                         if (jsonObject.getLong(&quot;occurTime&quot;) &gt; maxTime) {
                             maxTime = jsonObject.getLong(&quot;occurTime&quot;);
                         }
                         sum += 1;
                     }
                     out.collect(new Tuple3&lt;&gt;(s, sum, timeStamp2Date(maxTime)));
                 }
             }).print();
     env.execute();
 }
     public static String timeStamp2Date(Long time) {
     String seconds = String.valueOf(time);
     if (seconds == null || seconds.isEmpty() || seconds.equals(&quot;null&quot;)) {
         return &quot;&quot;;
     }
     SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;);
     return sdf.format(new Date(Long.valueOf(seconds)));
 }
     private static class JsonFormatDeserializer implements DeserializationSchema&lt;JSONObject&gt; {
     @Override
     public JSONObject deserialize(byte[] message) throws IOException {
         try {
             return JSON.parseObject(message, JSONObject.class);
         } catch (Exception e) {
             return null;
         }
     }

     @Override
     public boolean isEndOfStream(JSONObject nextElement) {
         return false;
     }

     @Override
     public TypeInformation&lt;JSONObject&gt; getProducedType() {
         return TypeInformation.of(JSONObject.class);
     }
 }
}
</code></pre>
</li>
<li>运行结果片段<br>
<img src="https://wangyemao-github.github.io/post-images/1610698549901.png" alt="" loading="lazy"><br>
以上就是一个基于Event Time，自定义时间戳提取以及水印生成的Flink消费kafka数据的简单实例。除了在数据源处提取时间戳，生成水印之外，还能在一些简单的操作之后再指定相关生成策略。具体可以参见Flink#WarkMark。</li>
</ol>
<h1 id="总结">总结</h1>
<ol>
<li>本文首先对Flink支持的多种时间概念，包括：Processing Time、Event Time、Ingestion Time 的定义、内涵、差异进行了详细说明，并给出了Flink应用程序中如何设置时间特性</li>
<li>WaterMark是Flink基于时间操作中的一个很重要的概念，本节简要地对WaterMark的作用进行说明</li>
<li>之后，基于Flink1.8版本，本文对三种时间特性下，Flink在数据源处如何提取时间戳、如何生成水印并发送到下游进行了解读</li>
<li>接着，本文结合源码分析了Flink-kafka-source-connector时间戳提取和水印生成进行说明</li>
<li>最后，基于Flink消费kafka数据场景，给出了一个简单的在源处提取时间戳和生成水印的实例。</li>
</ol>
<h1 id="相关参考">相关参考</h1>
<ol>
<li>https://ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html</li>
<li>http://www.54tianzhisheng.cn/2018/12/11/Flink-time/</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink State 之 KeyedState]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zhi-keyedstate/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zhi-keyedstate/">
        </link>
        <updated>2021-01-03T02:44:22.000Z</updated>
        <summary type="html"><![CDATA[<p>本文主要总结Flink State 中KeyedState，以及KeyedState的应用</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文主要总结Flink State 中KeyedState，以及KeyedState的应用</p>
<!-- more -->
<h1 id="keyedstate">KeyedState</h1>
<p>KeyedState在KeyedStream中使用。状态跟特定Key绑定的，即KeyedStream流上的每一个Key对应一个State对象。。</p>
<h2 id="keyedstate-支持的状态类型">KeyedState 支持的状态类型</h2>
<p>KeyedState可以使用所有Flink支持的State类型。FoldingState跟ReducingState类似，但是已标记为废弃，不建议再使用<br>
<img src="https://wangyemao-github.github.io/post-images/1609670108841.png" alt="" loading="lazy"></p>
<h2 id="statedescriptor">StateDescriptor</h2>
<p>对应于每一类State，Flink内部都设计了对应的<strong>StateDescriptor</strong>状态描述。它指定了状态的一些属性，包括：State名称，State中类型信息，序列化/反序列化器，State生存时间等。</p>
<h3 id="valuestatedescriptor定义">ValueStateDescriptor定义</h3>
<pre><code class="language-java">ValueStateDescriptor&lt;Tuple2&lt;Long,Long&gt;&gt; descriptor = 
              new ValueStateDescriptor&lt;&gt;(&quot;average&quot;,
                    TypeInformation.of(new TypeHint&lt;Tuple2&lt;Long,Long&gt;&gt;(){}),
                    Tuple2.of(0L,0L));
</code></pre>
<p>代码片段定义了一个ValueStateDescriptor，指定状态名称为“average”，状态类型为Tuple2&lt;Long,Long&gt;，默认值为：Tuple2&lt;0L,0L&gt;</p>
<h2 id="不同状态类型详细对比">不同状态类型详细对比</h2>
<table>
<thead>
<tr>
<th>State类型</th>
<th>存储数据类型</th>
<th>StateDescriptor</th>
<th>使用</th>
<th>操作</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueState<T></td>
<td>T类型的单值状态</td>
<td>ValueStateDescriptor<T></td>
<td>ValueState<T> getState(ValueStateDescriptor<T>)</td>
<td>更新：update(T);<br>获取：T value();</td>
<td>每一个Key与T类型状态值绑定</td>
</tr>
<tr>
<td>ListState<T></td>
<td>Key上的状态值为一个列表</td>
<td>ListStateDescriptor<T></td>
<td>ListState<T> getListState(ListStateDescriptor<T>)</td>
<td>追加数据：add(T)/addAll(List<T>);<br>获取状态数据列表：Iterable<T> get()</td>
<td></td>
</tr>
<tr>
<td>ReducingState<T></td>
<td>存储一个T类型的值</td>
<td>ReducingStateDescriptor<T></td>
<td>ReducingState<T> getReducingState(ReducingStateDescriptor<T>)</td>
<td>添加数据：add(T);</td>
<td>这种状态通过用户传入的reduceFunction，每次调用add方法添加值时，会调用reduceFunction，最后合并到一个单一的状态值</td>
</tr>
<tr>
<td>AggregatingState&lt;IN, OUT&gt;</td>
<td>存储一个值</td>
<td>AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;</td>
<td>AggregatingState&lt;IN, OUT&gt; getAggregatingState(AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;)</td>
<td>添加数据：add(IN)</td>
<td>聚合State，与ReducingState不同的是，这里的聚合类型可以是不同的元素类型。每次添加值时，会调用AggregateFunction函数计算聚合结果</td>
</tr>
<tr>
<td>MapState&lt;UK, UV&gt;</td>
<td>Map</td>
<td>MapStateDescriptor&lt;UK,UV&gt;</td>
<td>MapState&lt;UK, UV&gt; getMapState(MapStateDescriptor&lt;UK, UV&gt;)</td>
<td>添加：put(UK,UV)/putAll(UK,UV);<br>获取：UV get(UK);<br>遍历：Iterable&lt;Map.Entry&gt; entries()/Iterator&lt;Map.Entry&gt; iterator();</td>
<td>key-value结构数据</td>
</tr>
</tbody>
</table>
<h1 id="keyedstate使用">KeyedState使用</h1>
<p>##KeyedStream<br>
KeyedState只能应用于KeyedStream，如果你想在DataStream上使用Keyed State，你需要首先指定<strong>Key</strong>，Key用于State（也用于流记录本身）的分区。<br>
###指定Key的方式<br>
DataStream的keyBy()方法用于指定Key，并将DataStream转换为KeyedStream。它有如下几种重载方法，官方</p>
<blockquote>
<p>KeySelector</p>
<blockquote>
<p>KeyedStream&lt;T, K&gt; keyBy(KeySelector&lt;T, K&gt; key)<br>
通过实现KeySelector Function中的getKey()方法，自由指定Key的提取<br>
Tuple Keys<br>
KeyedStream&lt;T, Tuple&gt; keyBy(int... fields)<br>
应用于数据类型为简单Tuple类型，通过Tuple下表索引指定Key，当指定多个时为组合键<br>
Expression Keys<br>
KeyedStream&lt;T, Tuple&gt; keyBy(String... fields)<br>
应用于复杂的Tuple类型或POJO类型，对于POJO类型，String参数用于指定字段名</p>
</blockquote>
</blockquote>
<p>Flink的数据模型并不是基于键值对的。因此，KeyedStream并不会将物理上将数据处理为键何值。Key是“虚拟的”：它被定义为在实际数据上用于指导分组操作的函数。</p>
<p>KeyedState保存在StateBackend中</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink State 之 Operator State 应用]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zhi-operator-state-ying-yong/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zhi-operator-state-ying-yong/">
        </link>
        <updated>2020-12-29T12:34:38.000Z</updated>
        <summary type="html"><![CDATA[<p>上文已经说到：Flink中，根据数据集是否根据Key进行分区，将状态分为Keyde State和Operator State两种类型。本文主要关注Operator State以及Operator State相关应用。</p>
]]></summary>
        <content type="html"><![CDATA[<p>上文已经说到：Flink中，根据数据集是否根据Key进行分区，将状态分为Keyde State和Operator State两种类型。本文主要关注Operator State以及Operator State相关应用。</p>
<!-- more -->  
<h1 id="operator-state">Operator State</h1>
<p>Operator State，也称作non-keyed State。每一个Operator State与一个并行的Operator实例绑定，每个Operator实例中都持有所有数据元素的一部分状态。<br>
在典型的Flink有状态应用中，并不需要用到Operator State。它主要是作为一种特殊类型的状态，应用于Source/Sink的实现，以及在没有键进行状态分区的场景。</p>
<h2 id="支持的数据类型">支持的数据类型</h2>
<p>目前Operator State只支持使用<strong>ListState</strong></p>
<h2 id="重分布机制">重分布机制</h2>
<p>当并行度改变时，Operator State接口支持在并行的操作实例之间重分布State，并且支持多种重分布方案：</p>
<ul>
<li>均匀重分布：每一个并行Operator都返回一个状态列表（List）。整个状态空间逻辑上就是所有状态列表的并集。在恢复/重分布阶段，整个状态列表根据并行操作数目均分为子状态列表。每一个并行操作分配一个子状态列表，子状态列表可能为空，也可能包含一个或多个元素。</li>
<li>合并重分布：这种方式将状态的划分交给用户，与均匀重分布方式相比具有更好的灵活性。在恢复/重分布阶段，每一个并行操作都获得了完整的一份状态列表。如果状态基数很大，不建议使用这种方式。因为Checkpoint 元数据会存储每个列表项的偏移量，这可能导致RPC帧大小或内存不足错误。</li>
</ul>
<h1 id="operator-state-应用">Operator State 应用</h1>
<h2 id="如何初始化一个状态state">如何初始化一个状态(State)</h2>
<p>在Flink中，使用状态描述<strong>StateDescriptor</strong>来初始化State，它包含了State的名称以及保存的State值的类型信息</p>
<pre><code class="language-java">ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =
    new ListStateDescriptor&lt;&gt;(
        &quot;buffered-elements&quot;,
        TypeInformation.of(new TypeHint&lt;Tuple2&lt;String,Integer&gt;&gt;() {}));
</code></pre>
<p>上面的代码片段中定义了一个State名称为：buffered-elements，State值类型为：Tuple2&lt;String,Integer&gt; 的状态描述<br>
##CheckpointedFunction<br>
要使用Operator State，有状态的函数需要实现<strong>CheckpointedFunction</strong>接口，该接口需要实现两个方法：</p>
<pre><code class="language-java">void snapshotState(FunctionSnapshotContext context) throws Exception;
void initializeState(FunctionInitializationContext context) throws Exception;
</code></pre>
<p>无论什么时候执行checkpoint，都会调用snapshotState()方法。因此该方法主要定义状态的快照保存逻辑；相应地，每当用户定义的函数被初始化时（无论是函数首次初始化，还是函数实际上从更早一个检查点恢复），都会调用initializeState()方法。因此，initializeState()不仅是不同类型状态初始化的地方，而且也包含了状态恢复的逻辑。</p>
<h2 id="sinkfunction-sample">SinkFunction Sample</h2>
<pre><code class="language-java">public class BufferingSink implements SinkFunction&lt;Tuple2&lt;String, Integer&gt;&gt;,            CheckpointedFunction {

    private final int threshold;

    private transient ListState&lt;Tuple2&lt;String, Integer&gt;&gt; checkpointedState;

    private List&lt;Tuple2&lt;String, Integer&gt;&gt; bufferedElements;

    public BufferingSink(int threshold) {
        this.threshold = threshold;
        this.bufferedElements = new ArrayList&lt;&gt;();
    }

    @Override
    public void invoke(Tuple2&lt;String, Integer&gt; value, Context contex) throws Exception {
        bufferedElements.add(value);
        if (bufferedElements.size() == threshold) {
            for (Tuple2&lt;String, Integer&gt; element: bufferedElements) {
                // send it to the sink
            }
            bufferedElements.clear();
        }
    }

    @Override
    public void snapshotState(FunctionSnapshotContext context) throws Exception {
        checkpointedState.clear();
        for (Tuple2&lt;String, Integer&gt; element : bufferedElements) {
            checkpointedState.add(element);
        }
    }

    @Override
    public void initializeState(FunctionInitializationContext context) throws Exception {
        ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =
            new ListStateDescriptor&lt;&gt;(
                &quot;buffered-elements&quot;,
                TypeInformation.of(new TypeHint&lt;Tuple2&lt;String, Integer&gt;&gt;() {}));

        checkpointedState = context.getOperatorStateStore().getListState(descriptor);

        if (context.isRestored()) {
            for (Tuple2&lt;String, Integer&gt; element : checkpointedState.get()) {
                bufferedElements.add(element);
            }
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink State 之总体介绍]]></title>
        <id>https://wangyemao-github.github.io/post/flink-state-zong-ti-jie-shao/</id>
        <link href="https://wangyemao-github.github.io/post/flink-state-zong-ti-jie-shao/">
        </link>
        <updated>2020-12-29T08:09:21.000Z</updated>
        <summary type="html"><![CDATA[<p>本文主要对Flink State进行整体介绍，包括有状态的流式计算框架Flink与传统流式计算框架的区别，Flink State类型划分，State存储与管理以及动态扩容。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文主要对Flink State进行整体介绍，包括有状态的流式计算框架Flink与传统流式计算框架的区别，Flink State类型划分，State存储与管理以及动态扩容。</p>
<!-- more -->
<h1 id="一-有状态流计算介绍">一、有状态流计算介绍</h1>
<h2 id="什么是有状态的计算">什么是有状态的计算</h2>
<p>计算任务的结果不仅仅依赖于输入，还依赖于它的当前状态。比如，很常见的业务场景wordCount，在计算的过程中要不断地把输入累加到count上去，那么<strong>这里的count就是一个state</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609229474736.jpg" alt="" loading="lazy"><br>
Flink基于用户定义代码对到来的数据进行转换操作，处理过程中不仅依赖用户定义算子，还会涉及State数据的读写操作。这些State数据会存储在本地的State backend中，在Checkpoint的时候持久化到配置的Checkpoint 目录</p>
<h2 id="传统流式框架">传统流式框架</h2>
<p>在之前的实时计算框架—Spark进行流式数据处理过程中，流式计算通过将源源不断的数据切分为一个个很小的时间间隔批块，然后针对每一个微批块进行数据计算。它并不是真正意义上的流式处理。每一个微批，只需要保存最终的计算结果，因此，它对于State的需求还是比较小的。</p>
<p>实际上，流式计算对State的要求是非常高的。因为流系统中输入是一个无限制的流，需要保证很长一段时间持续不间断运行，这个过程中就需要很好地将状态数据管理起来。传统的流式计算框架缺乏对State的有效支持：</p>
<ul>
<li>状态数据的存储和访问</li>
<li>状态数据的备份和恢复</li>
<li>状态数据的划分和动态扩容</li>
</ul>
<h2 id="flink提供了丰富的状态访问和高效的容错机制">Flink提供了丰富的状态访问和高效的容错机制</h2>
<ul>
<li>多种数据类型：Value、List、Map、Reducing、Folding、Aggregating</li>
<li>多种划分方式： Keyed State、Operator State</li>
<li>多种存储格式： MemoryStateBackend、FsStateBackend、RocksDBStateBackend</li>
<li>高效的备份和恢复：提供ExactlyOnce保证、增量及异步备份本地恢复</li>
</ul>
<h1 id="二-flink-state-类别">二、Flink State 类别</h1>
<p>Flink中，State按照是否有Key划分为Keyed State和Operator State</p>
<h2 id="keyed-state">Keyed State</h2>
<p><strong>Keyed State</strong>在Keyed Stream中使用。状态是跟特定的Key绑定的，即Keyed Stream流上的每一个Key对应一个State对象。</p>
<h2 id="operator-state">Operator State</h2>
<p><strong>Operator State</strong>(non-keyed state)跟一个特定操作的并行实例绑定，整个操作只对应一个State。典型的Operator State应用场景就是Kafka Source Connector，kafka consumer的每一个并行实例都维护了topic partition与offsets的映射关系作为它的Operator State。<br>
<strong>Broadcast State</strong>是一个特殊的Operator State。它的引入是为了支持一个流的记录需要被广播到下游的所有并行任务的场景，在这种场景中，它们被用来在所有的并行任务中维护相同的状态。然后，可以在处理第二个流的记录时访问这个状态。broadcast state与operator state的其他区别：</p>
<ol>
<li>状态的数据类型为Map格式</li>
<li>它仅在具有两个输入流的特定操作上可用，一个输入流为broadcasted stream ，一个输入流为non-broadcasted</li>
<li>这些操作可以定义多个具有不同名称的broadcast state</li>
</ol>
<p><strong>详细对比：</strong></p>
<table>
<thead>
<tr>
<th>对比维度</th>
<th>Keyed State</th>
<th>Operator State</th>
</tr>
</thead>
<tbody>
<tr>
<td>使用场景</td>
<td>只能用于KeyedStream上的算子</td>
<td>可以用于所有的算子，常用于Source，例如FlinkKafkaConsumer</td>
</tr>
<tr>
<td>应用</td>
<td>通过RuntimeContext访问，操作函数需要实现RichFunction接口</td>
<td>实现CheckpointedFunction或ListCheckpointed接口</td>
</tr>
<tr>
<td>是否需要手动声明快照(snapshot)和恢复（restore)方法</td>
<td>由backend自行实现，对用户透明</td>
<td>需要手动实现snapshot和restore方法</td>
</tr>
<tr>
<td>支持数据接口</td>
<td>包括：ValueState、ListState、ReducingState、AggregatingState、MapState</td>
<td>ListState。特别说明：Broadcast State 是MapState类型</td>
</tr>
<tr>
<td>是否存在当前处理的 key（current key）</td>
<td>keyed state的value总是与一个current key对应。一个Operator实例处理多个key，访问相应的多个State</td>
<td>无当前key概念。一个Operator实例对应一个State</td>
</tr>
<tr>
<td>并发改变时State重分布</td>
<td>基于Key-Group，State随着Key在实例间迁移</td>
<td>并发改变时，有多种重新分配方式可选：均匀分配；合并后每个实例都得到全量状态</td>
</tr>
<tr>
<td>存储对象是否 on heap</td>
<td>keyed state backend 有on-heap和off-heap(RocksDB)的多种实现</td>
<td>目前operator state backend仅有一种on-heap的实现</td>
</tr>
<tr>
<td>状态数据大小【这只是个经验判断，不是绝对的判断区分标准】</td>
<td>一般而言，Keyed state规模的相对比较大的</td>
<td>一般而言，我们认为operator state的数据规模是比较小的</td>
</tr>
</tbody>
</table>
<h1 id="三-flink-state存储和管理">三、Flink State存储和管理</h1>
<h2 id="state-backend-分类">State Backend 分类</h2>
<p>State在内部如何表述，checkpoint时，State如何以及在哪里进行持久化，依赖于选择的State Backend。Flink默认捆绑了三类State Backends：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。在未配置的情况下，系统将默认使用MemoryStateBackend。</p>
<p><strong>详细区别：</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609232674288.jpg" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>State Backend 类型</th>
<th>State存储</th>
<th>Checkpoint时存储</th>
<th>快照方式</th>
<th>是否支持增量Checkpoint</th>
<th>限制</th>
<th>使用场景</th>
<th>推荐设置</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>MemoryStateBackend</td>
<td>TaskManager内存</td>
<td>JobManager内存</td>
<td>默认异步方式</td>
<td>否</td>
<td>1. 单个State默认限制为5MB，当然这个值可以在创建state backend时调整<br>2. 但是Max State最大不能超过akka frame的size (默认10M)<br>3. 聚合的State总大小要小于JobManager内存大小</td>
<td>1. 本地开发和debugging<br>2. 需要存储很少量状态的作业<br>3. 不推荐生产场景</td>
<td>将managed memory设置为0.确保最大量地使用分配内存给用户作业</td>
<td>1. State数据作为Java堆对象在本地（TaskManager）存储<br>2. 在Checkpoint时，state backend会快照状态数据，作为checkpoint确认消息的一部分发送给JobManager。在JobManager上，状态数据也是在Java 堆上存储的</td>
</tr>
<tr>
<td>FsStateBackend</td>
<td>TaskManager内存</td>
<td>外部文件系统（本地目录或HDFS目录）</td>
<td>默认异步方式</td>
<td>否</td>
<td>1.单Taskmanager上的State总量不超过它的内存<br>2.总大小不超过配置的文件系统容量</td>
<td>1.大状态作业，长窗口，大key/value 状态<br>2.高可用设置<br>3.生产场景</td>
<td>同上</td>
<td>1.在TaskManager的内存中，存储正在使用的State数据<br>2. Checkpointing时，state backend将状态快照写文件到配置文件系统和目录中。最小化的元数据存储在JobManager的内存【状态数据存储的路径】（高可用模式，存储元数据在元数据checkpoint路径）</td>
</tr>
<tr>
<td>RocksDBStateBackend</td>
<td>TaskManager上的KV数据库(RocksDB)【实际使用内存+磁盘】</td>
<td>外部文件系统（本地目录或HDFS目录）</td>
<td>总是异步</td>
<td>是</td>
<td>1.单TaskManager上的State不超过它的内存+磁盘<br>2.单Key最大2G<br>3.总大小不超过配置的文件系统容量</td>
<td>1.大状态作业，长窗口，大key/value 状态<br>2.高可用设置<br>3.生产场景</td>
<td></td>
<td>1.RocksDBStateBackend在RocksDB数据库中保存正在使用的状态数据，默认存储在TaskManager的数据目录<br>2.在checkpointing时，整个RocksDB数据库将被快照到配置的文件系统或目录。最小化的元数据存储在JobManager的内存中（高可用模式，存储在元数据checkpoint目录）</td>
</tr>
</tbody>
</table>
<p><strong>关于RocksDBStateBackend的特别说明：</strong></p>
<ol>
<li>这种方式可以维持的状态量只受限于可用的磁盘空间。与FsStateBackend将state存储在内存相比，这种方式允许保留更大的state</li>
<li>但是，这也意味着，可以获取的最大吞吐量将比FsStateBackend方式的低</li>
<li>所有对backend的read/write都需要通过序列化/反序列化，以存储/获取状态对象。这种方式与基于堆的存储方式代价更高</li>
</ol>
<h2 id="state-backend配置">State Backend配置</h2>
<ul>
<li>配置默认State Backend</li>
</ul>
<blockquote>
<p>flink-conf.yml<br>
state.backend: 【可能的取值：jobmanager(MemoryStateBackend)、fileSystem(FsStateBackend)、rocksdb(RocksDBStateBackend)、或者实现了state backend factory StateBackendFactory的全限定类名（org.apache.flink.contrib.streaming.state.RocksDBStateBackendFactory）】<br>
state.checkpoints.dir:定义backend写快照数据和元数据文件的目录</p>
</blockquote>
<ul>
<li>per-job 设置State Backend</li>
</ul>
<blockquote>
<p>StreamExecutionEnvironment</p>
</blockquote>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setStateBackend(new FsStateBackend(&quot;hdfs://namenode:40010/flink/checkpoints&quot;));
</code></pre>
<h1 id="四-flink-state-划分和动态扩容">四、Flink State 划分和动态扩容</h1>
<h2 id="state-划分">State 划分</h2>
<ul>
<li>对于Operator State类型，每一个并行的Operator实例对应一个State</li>
<li>对于Keyed State类型，每一个Current Key对应一个State</li>
</ul>
<h2 id="state-动态扩容">State 动态扩容</h2>
<p><strong>Operator State类型</strong><br>
<img src="https://wangyemao-github.github.io/post-images/1609232700062.jpg" alt="" loading="lazy"></p>
<ul>
<li>ListState：并发度改变的时候，会将并发实例上的ListState都合并到一个新的List，然后均匀分配到变更后的并发Task上</li>
<li>UnionListState：每一个并发Task都会拿到全量的ListState</li>
<li>BroadcastState：每个并发Task上的State都是完全一致的，因此，当增大并发度时，只需要Copy一份State到新Task即可</li>
</ul>
<p><strong>Keyed State类型</strong><br>
在并行度改变时，如何重分布KeyedState数据，最直观的做法就是计算每个Key的Hash值，并基于并行度parallelism取余。下图为当并行度改变时，基于Hash取余算法的State数据重分布情况：<br>
<img src="https://wangyemao-github.github.io/post-images/1609232708709.png" alt="" loading="lazy"></p>
<p>hash取余重分布算法存在的问题：之前在各个Task上维护好的State数据会根据新的并行度重新组织，State数据在各个Task之间传输。这对于KeyedState数据较大时，数据重新组织的代价会很高。</p>
<p>为了规避上述问题，Flink基于Key-Group(KeyedState的最小组织单位)组织、分配KeyedState。具体的映射关系为</p>
<pre><code class="language-java">public static int assignToKeyGroup(Object key, int maxParallelism) {
   return computeKeyGroupForKeyHash(key.hashCode(), maxParallelism);
}
public static int computeKeyGroupForKeyHash(int keyHash, int maxParallelism) {
   return MathUtils.murmurHash(keyHash) % maxParallelism;
}
</code></pre>
<p>也就是说，Key-Group数量取决于最大并行度（MaxParallism），只要最大并行度不变，同一个key归属的Key-Group是不会变更的。另外，此处在HashCode的基础上又调用murmurHash方法是为了保证尽量散列。</p>
<p>在对Key划分Key-Group之后，MaxParallism个Key-Group 基于KeyGroupRange分配到parallelism个并行Task中，每一个并行Task持有1个KeyGroupRange，具体计算方法：</p>
<pre><code>public static KeyGroupRange computeKeyGroupRangeForOperatorIndex(
   int maxParallelism,
   int parallelism,
   int operatorIndex) {
   int start = ((operatorIndex * maxParallelism + parallelism - 1) / parallelism);
   int end = ((operatorIndex + 1) * maxParallelism - 1) / parallelism;
   return new KeyGroupRange(start, end);
}
</code></pre>
<p><strong>以一个具体的实例说明：</strong><br>
对于一个Key 空间=[0,1,2,3,4,5,6,7,8,9] 的数据，MaxParallelism=5，并行度Parallelism由2扩大到3的过程中， 各个并行Task的Key-Group重分布情况为：<br>
<img src="https://wangyemao-github.github.io/post-images/1609232723011.png" alt="" loading="lazy"><br>
<strong>总结：</strong></p>
<ol>
<li>只要MaxParallelism不变，整个Key空间的Key-Group划分情况是不会变更的</li>
<li>当并行度变更时，基于Key-Group，将Key-Group重新分配到并行Task中，并且这种重新分配不是一个Shuffle，Key-Group归属的并行Task的变更很小。</li>
</ol>
<p>参考资料：<br>
https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state.html<br>
https://ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/state_backends.html<br>
http://www.54tianzhisheng.cn/2019/06/18/flink-state/</p>
]]></content>
    </entry>
</feed>